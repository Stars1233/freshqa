{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cIMEmj9Esik",
        "outputId": "b8953f3b-8ff6-42b5-ff15-af0aaf05406d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "#@title Installing required Python packages\n",
        "\n",
        "\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importing Python libraries and modules\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "import pytz\n",
        "import dateutil\n",
        "import requests\n",
        "import json\n",
        "import csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "from openai import OpenAI\n",
        "import tabulate\n",
        "import textwrap\n",
        "\n",
        "\n",
        "current_date = datetime.datetime.now(\n",
        "        pytz.timezone(\"America/Los_Angeles\")\n",
        "    ).strftime(\"%B %d, %Y\")\n"
      ],
      "metadata": {
        "id": "wW3P9qyxHHU8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title API keys\n",
        "\n",
        "\n",
        "# OpenAI's API key (sign up at https://platform.openai.com/signup to get $5 in\n",
        "# free credit that can be used during your first 3 months)\n",
        "openai_api_key = \"\"  # @param {type:\"string\"}\n",
        "openai_client = OpenAI(\n",
        "  api_key=openai_api_key,\n",
        ")\n",
        "\n",
        "assert (\n",
        "      openai_api_key is not None and openai_api_key != ''\n",
        "  ), \"OpenAI's API key is not set\"\n"
      ],
      "metadata": {
        "id": "98YRRHnz0SGu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function calling for the base LLM\n",
        "\n",
        "\n",
        "def call_llm_api(prompt, model, temperature, max_tokens, chat_completions=True):\n",
        "  # See https://platform.openai.com/docs/guides/gpt for details\n",
        "  if chat_completions:\n",
        "    # Chat completions API\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You are a helpful assistant. Respond as concisely as\"\n",
        "                    f\" possible. Knowledge cutoff: {current_date}.\"\n",
        "                ),\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": \"What's today's date?\"},\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": f\"Today is {current_date} in Pacific Standard Time.\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "  else:\n",
        "    # Completions API\n",
        "    response = openai_client.completions.create(\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        prompt=prompt,\n",
        "    )\n",
        "    return response.choices[0].text\n"
      ],
      "metadata": {
        "id": "7x4S8-FHHtK1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instructions & demonstration examples\n",
        "\n",
        "\n",
        "prefix = (\n",
        "    \"Please evaluate the response to a question under strict evaluation, where\"\n",
        "    \" no hallucinations, outdated information, or ill-formed answers are\"\n",
        "    \" allowed. Please credit the response only if it provides a confident and\"\n",
        "    \" definitive answer, or the correct answer can be obviously inferred from\"\n",
        "    \" the response. The primary or final answer when standing alone must be\"\n",
        "    \" accurate. Any additional information that is provided must not contradict\"\n",
        "    \" the primary answer or reshape one's perception of it. For false-premise\"\n",
        "    \" questions, the response must point out the presence of a false premise to\"\n",
        "    \" receive credit. For answers that involve names of entities (e.g.,\"\n",
        "    \" people), complete names or commonly recognized names are expected.\"\n",
        "    \" Regarding numerical answers, approximate numbers are generally not\"\n",
        "    \" accepted unless explicitly included in the ground-truth answers. A\"\n",
        "    \" response that contains any hallucination, no matter how minor, will not\"\n",
        "    \" receive credit. Furthermore, when the response indicates that the\"\n",
        "    \" information might be outdated, we accept it only if it is evident that\"\n",
        "    \" the knowledge has not changed (e.g., through common sense or well-known\"\n",
        "    \" facts).\"\n",
        ")\n",
        "\n",
        "demo_examples = [\n",
        "    {\n",
        "        \"question\": \"How old is the world's oldest verified living person?\",\n",
        "        \"correct_answers\": [\n",
        "            \"116 years old\",\n",
        "            \"116\",\n",
        "            \"nearly 117 years old\",\n",
        "        ],\n",
        "        \"response\": (\n",
        "            f\"As of today {current_date}, the most up-to-date and relevant\"\n",
        "            \" information regarding this query is as follows. The oldest\"\n",
        "            \" verified living person is Maria Branyas Morera, who was born\"\n",
        "            \" on March 4, 1907, making her 116 years old.\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. The primary answer in the response\"\n",
        "            \" (116 years old) is accurate, and all the provided information\"\n",
        "            \" is accurate and up-to-date. Thus, the response is credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"correct\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"When did the UK adopt the Euro?\",\n",
        "        \"correct_answers\": [\"The United Kingdom has never adopted the Euro.\"],\n",
        "        \"response\": (\n",
        "            \"The UK has never adopted the Euro as its official currency. The\"\n",
        "            \" country has retained the British pound sterling (GBP) as its\"\n",
        "            \" currency.\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"The question contains a false premise. The response debunks the\"\n",
        "            \" question's false premise (i.e., it points out that the UK has\"\n",
        "            \" never adopted the Euro), and all the provided information is\"\n",
        "            \" accurate and up-to-date. Thus, the response is credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"correct\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": (\n",
        "            \"How much longer will Brittney Griner spend in the Russian prison?\"\n",
        "        ),\n",
        "        \"correct_answers\": [\n",
        "            \"She was released in December 2022 as part of a prisoner swap.\"\n",
        "        ],\n",
        "        \"response\": (\n",
        "            \"I'm sorry, but I have no information to suggest that Brittney\"\n",
        "            \" Griner is currently in a Russian prison. As far as I know, she\"\n",
        "            \" is a professional basketball player who currently plays for the\"\n",
        "            \" Phoenix Mercury in the Women's National Basketball Association\"\n",
        "            \" (WNBA). If you have any more information or context, please let\"\n",
        "            \" me know and I'll do my best to help.\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"The question contains a false premise. The response fails to\"\n",
        "            \" debunk the question's false premise by not explicitly stating\"\n",
        "            \" that Brittney Griner was already released. Additionally, the\"\n",
        "            \" response lacks a confident and definitive answer. Thus, the\"\n",
        "            \" response is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": (\n",
        "            \"Which language has the third largest population by number of\"\n",
        "            \" native speakers?\"\n",
        "        ),\n",
        "        \"correct_answers\": [\"English\"],\n",
        "        \"response\": \"1. Mandarin 2. Spanish 3. English\",\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. While the correct answer (English) can\"\n",
        "            \" be inferred from the response, the response lacks an explicit\"\n",
        "            \" statement, which is not desirable.\"\n",
        "            \" Thus, the response is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": (\n",
        "            \"Has Virginia Woolf's novel about the Ramsay family entered the\"\n",
        "            \" public domain in the United States?\"\n",
        "        ),\n",
        "        \"correct_answers\": [\"Yes\"],\n",
        "        \"response\": (\n",
        "            \"1927's To the Lighthouse is in the public domain in the United\"\n",
        "            \" States. The final answer is To the Lighthouse.\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. While the primary information in the\"\n",
        "            \" response (1927's To the Lighthouse is in the public domain in\"\n",
        "            \" the United States) is accurate, the final answer when standing\"\n",
        "            ' alone is inaccurate (it should be \"Yes\" instead of \"To the'\n",
        "            ' Lighthouse\"). Thus, the response is not credited.'\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Is Tesla's stock price above $250 a share?\",\n",
        "        \"correct_answers\": [\"No\"],\n",
        "        \"response\": \"No, it isn't. The stock price is currently at $257.\",\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. While the primary answer in the\"\n",
        "            \" response (No) is accurate, the additional information\"\n",
        "            \" contradicts the primary answer (\$257 is above \$250). Thus,\"\n",
        "            \" the response is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"When did Lionel Messi win his second FIFA World Cup?\",\n",
        "        \"correct_answers\": [\n",
        "            \"Messi has not won his second FIFA World Cup.\",\n",
        "            \"Messi has won only one FIFA World Cup.\",\n",
        "        ],\n",
        "        \"response\": (\n",
        "            \"This question does not contain a valid premise. Lionel Messi has\"\n",
        "            \" never won a FIFA World Cup.\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"The question contains a false premise. While the response\"\n",
        "            \" debunks the question's false premise (i.e., it suggests that\"\n",
        "            \" Messi has not won his second FIFA World Cup), it inaccurately\"\n",
        "            \" shapes one's knowledge perception of the primary answer, as\"\n",
        "            \" Messi has already won one FIFA World Cup. Thus,\"\n",
        "            \" the response is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": (\n",
        "            \"How many times has Jeremy Corbyn served as Prime Minister of\"\n",
        "            \" the UK?\"\n",
        "        ),\n",
        "        \"correct_answers\": [\n",
        "            \"Corbyn has never served as Prime Minister of the UK.\"\n",
        "        ],\n",
        "        \"response\": \"Zero\",\n",
        "        \"comment\": (\n",
        "            \"The question contains a false premise. The response lacks a\"\n",
        "            \" rebuttal, which is always required for false-premise questions.\"\n",
        "            \" Thus, the response is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Who founded Amazon?\",\n",
        "        \"correct_answers\": [\"Jeff Bezos\", \"Jeffrey Preston Bezos\"],\n",
        "        \"response\": \"100% of people said Jeff.\",\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. Given that the question involves a\"\n",
        "            \" person's name, a complete name or commonly recognized name is\"\n",
        "            ' expected (\"Jeff Bezos\" instead of \"Jeff\"). Thus, the response'\n",
        "            \" is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How many books has Colleen Hoover published?\",\n",
        "        \"correct_answers\": [\"26 books\", \"26\"],\n",
        "        \"response\": (\n",
        "            f\"As of today {current_date}, the most up-to-date and relevant\"\n",
        "            \" information regarding this query is as follows. Colleen Hoover\"\n",
        "            \" has published over 20 books and novellas.\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. For a numerical answer, an approximate\"\n",
        "            \" value (over 20 books) is generally not accepted unless\"\n",
        "            \" explicitly included in the correct answers. Thus, the response\"\n",
        "            \" is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the largest model size of GPT-3?\",\n",
        "        \"correct_answers\": [\n",
        "            \"175 billion parameters\",\n",
        "            \"175B parameters\",\n",
        "            \"175 billion\",\n",
        "            \"175B\",\n",
        "        ],\n",
        "        \"response\": (\n",
        "            \"175 billion parameters. It is a 175 billion parameter, 1.37TB,\"\n",
        "            \" 137B token, 137B wordpiece, 137B BPE, 137B byte pair encoding,\"\n",
        "            \" 137B BPE token, 137B BPE wordpiece, 137B BPE token, 137B BPE\"\n",
        "            \" wordpiece\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. While the primary answer in the response\"\n",
        "            \" (175 billion parameters) is accurate, the response is ill-formed\"\n",
        "            \" and contains repetitions. Thus, the response is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How many member nations exist in the United Nations?\",\n",
        "        \"correct_answers\": [\n",
        "            \"193\",\n",
        "            \"193 members\",\n",
        "            \"193 member states\",\n",
        "            \"193 sovereign states\",\n",
        "        ],\n",
        "        \"response\": (\n",
        "            \"As of my knowledge cutoff date in January 2022, there were 193\"\n",
        "            \" member nations in the United Nations. Please note that this\"\n",
        "            \" information may have changed since then, so it is advisable to\"\n",
        "            \" check the latest information from the United Nations or other\"\n",
        "            \" reliable sources.\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. The primary answer in the response (193\"\n",
        "            \" member nations) is accurate. However, the response fails to\"\n",
        "            \" provide a current answer and instead relies on outdated \"\n",
        "            \" information without confirming its continued accuracy. Thus, the\"\n",
        "            \" response is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": (\n",
        "            \"Who won the biggest single-tournament payday in tennis history?\"\n",
        "        ),\n",
        "        \"correct_answers\": [\"Novak Djokovic\"],\n",
        "        \"response\": (\n",
        "            \"The biggest single-tournament payday in tennis history was won\"\n",
        "            \" by Novak Djokovic at the 2021 Australian Open. He received a\"\n",
        "            \" prize money of AUD 2.75 million (approximately USD 2.1 million)\"\n",
        "            \" for winning the men's singles title.\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. While the primary answer in the\"\n",
        "            \" response (Novak Djokovic) is accurate, the additional provided\"\n",
        "            \" information is outdated or hallucinated (by winning the 2022\"\n",
        "            \" ATP Finals title, Djokovic earned a record $4,740,300, the\"\n",
        "            \" highest payout for a tournament winner in tennis). Thus, the\"\n",
        "            \" response is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": (\n",
        "            \"Who was the first football player to score one hundred\"\n",
        "            \" international goals?\"\n",
        "        ),\n",
        "        \"correct_answers\": [\"Ali Daei\"],\n",
        "        \"response\": (\n",
        "            \"As of my knowledge cutoff date in January 2022, Ali Daei, a\"\n",
        "            \" former Iranian footballer, was the first player to score 100\"\n",
        "            \" international goals.\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. The primary answer in the response\"\n",
        "            \" (Ali Daei) is accurate. Although the knowledge cutoff date is\"\n",
        "            \" in 2021, this fact is timeless because Ali Daei was the initial\"\n",
        "            \" achiever of this milestone, and he will always remain the first).\"\n",
        "            \" Thus, the response is credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"correct\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": (\n",
        "            \"Who is the latest winner of the Formula 1 world championship?\"\n",
        "        ),\n",
        "        \"correct_answers\": [\"Max Verstappen\", \"Max Emilian Verstappen\"],\n",
        "        \"response\": (\n",
        "            \"Max Verstappen won the 2022 Formula 1 world championship. He is\"\n",
        "            \" a Dutch racing driver who competes in Formula One for Red Bull\"\n",
        "            \" Racing. He is the son of former Formula One driver Jos\"\n",
        "            \" Verstappen. Verstappen started his racing career in karting at\"\n",
        "            \" the age of seven. He won the 2013 European Karting Championship\"\n",
        "            \" and the 2013 World Karting Championship. In 2014, he moved to\"\n",
        "            \" single-seater racing, competing in the European Formula Three\"\n",
        "            \" Championship. He won the championship in his first season,\"\n",
        "            \" becoming the first driver to do so since Nico Rosberg in 2005.\"\n",
        "            \" In 2015, Verstappen moved to Formula One, driving for Toro\"\n",
        "            \" Rosso. He became the youngest driver to compete in Formula One\"\n",
        "            \" at the age of 17. He scored his first points in Formula One at\"\n",
        "            \" the 2015 Hungarian GrandPrix. In 2016, Verstappen moved to Red\"\n",
        "            \" Bull Racing. He won his first race at the 2016 Spanish Grand\"\n",
        "            \" Prix. He became the youngest driver to win a race in Formula\"\n",
        "            \" One at theage of 18. Verstappen finished the 2016 season in\"\n",
        "            \" third place in the drivers' championship. In 2017, Verstappen\"\n",
        "            \" won four races and finished the season in second place in the\"\n",
        "            \" drivers' championship. In 2018, Verstappen won seven races and\"\n",
        "            \" finished the season in second place in the drivers'\"\n",
        "            \" championship. In 2019, Verstappen won nine races and finished\"\n",
        "            \" the season in first place in the drivers' championship. He is\"\n",
        "            \" the first Dutch driver to win the Formula One world\"\n",
        "            \" championship.\"\n",
        "        ),\n",
        "        \"comment\": (\n",
        "            \"This is a valid question. While the primary answer in the\"\n",
        "            \" response (Max Verstappen) is accurate, the response contains\"\n",
        "            \" several instances of hallucinated information (e.g., Max\"\n",
        "            \" Verstappen did not win the Formula Three European Championship\"\n",
        "            \" in 2014). Thus, the response is not credited.\"\n",
        "        ),\n",
        "        \"evaluation\": \"incorrect\",\n",
        "    },\n",
        "]\n",
        "\n",
        "demo_questions = [ex[\"question\"] for ex in demo_examples]\n",
        "\n",
        "demo_evaluation_template = (\n",
        "    \"\\ncorrect answer(s): {correct_answers}\"\n",
        "    \"\\nresponse: {response}\"\n",
        "    \"\\ncomment: {comment}\"\n",
        "    \"\\nevaluation: {evaluation}\"\n",
        ")\n",
        "evaluation_template = (\n",
        "    \"\\ncorrect answer(s): {correct_answers}\"\n",
        "    \"\\nresponse: {response}\"\n",
        "    \"\\ncomment: \"\n",
        ")\n",
        "\n",
        "demo_evaluations = []\n",
        "for ex in demo_examples:\n",
        "  demo_evaluation = demo_evaluation_template.format(\n",
        "      question=ex[\"question\"],\n",
        "      correct_answers=' | '.join(ex[\"correct_answers\"]),\n",
        "      response=ex[\"response\"],\n",
        "      comment=ex[\"comment\"],\n",
        "      evaluation=ex[\"evaluation\"],\n",
        "  )\n",
        "  demo_evaluations.append(demo_evaluation)\n"
      ],
      "metadata": {
        "id": "xmQZYfPD3sxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function calling for FreshEval\n",
        "\n",
        "\n",
        "def call_fresheval(model, prefix, question, response, correct_answers,\n",
        "                   evaluation):\n",
        "  temperature = 0.0\n",
        "  max_tokens = 256\n",
        "  chat_completions = True\n",
        "\n",
        "  if model.startswith('gpt-4'):\n",
        "    num_organic_results = 15\n",
        "    num_related_questions = 3\n",
        "    num_questions_and_answers = 3\n",
        "    num_retrieved_evidences = 15\n",
        "  else:\n",
        "    num_organic_results = 15\n",
        "    num_related_questions = 2\n",
        "    num_questions_and_answers = 2\n",
        "    num_retrieved_evidences = 5\n",
        "\n",
        "  # Generate prompts for demo examples\n",
        "  demo_prompts = []\n",
        "  for q, e in zip(demo_questions, demo_evaluations):\n",
        "      demo_prompts.append(f'\\n\\n\\nquestion: {q}{e}')\n",
        "\n",
        "  fresheval_demo = ''.join(demo_prompts).strip()\n",
        "\n",
        "  fresheval_question = f'\\n\\n\\nquestion: {question}{evaluation}'\n",
        "\n",
        "  fresh_eval = prefix + '\\n\\n\\n' + fresheval_demo + fresheval_question\n",
        "  answer = call_llm_api(\n",
        "      fresh_eval, model, temperature, max_tokens, chat_completions\n",
        "  )\n",
        "\n",
        "  return answer\n",
        "\n",
        "\n",
        "def extract_ratings(response):\n",
        "  evaluation = None\n",
        "  for line in response.split('\\n'):\n",
        "    if 'evaluation: ' in line:\n",
        "      evaluation = line.split(' ')[-1]\n",
        "      if evaluation not in ['correct', 'incorrect']:\n",
        "        return False, {'rating': None}\n",
        "      if evaluation == 'incorrect':\n",
        "        evaluation = 'FALSE'\n",
        "      else:\n",
        "        evaluation = 'TRUE'\n",
        "  if evaluation is None:\n",
        "    if 'Thus, the response is credited.' in response:\n",
        "      evaluation = 'TRUE'\n",
        "    elif 'Thus, the response is not credited.' in response:\n",
        "      evaluation = 'FALSE'\n",
        "    else:\n",
        "      return False, {'rating': None}\n",
        "  return True, {'rating': evaluation}\n"
      ],
      "metadata": {
        "id": "fAcuImw5EP5T",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FreshEval\n",
        "\n",
        "\n",
        "# @markdown ---\n",
        "model_name = \"gpt-4-0125-preview\" #@param [\"gpt-4-0125-preview\", \"gpt-4-turbo-preview\", \"gpt-4-1106-preview\", \"gpt-4\", \"gpt-4-0613\", \"gpt-4-32k\", \"gpt-4-32k-0613\", \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-instruct\", \"gpt-3.5-turbo-0613\", \"gpt-3.5-turbo-16k-0613\", \"gpt-3.5-turbo-0301\"]\n",
        "evaluation_spreadsheet_name = \"fresheval_strict\" # @param {type:\"string\"}\n",
        "\n",
        "# In the following example, we evaluate the first 10 responses\n",
        "num_evals = 10\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "worksheet = gc.open(evaluation_spreadsheet_name).sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "# Convert to a DataFrame and render.\n",
        "df = pd.DataFrame.from_records(rows[3:], columns=rows[2])[:num_evals]\n",
        "\n",
        "freshevals = []\n",
        "for index, row in df.iterrows():\n",
        "  print(f'Evaluating example id={index}...')\n",
        "  question = row['question']\n",
        "  response = row['model_response']\n",
        "  correct_answers = [row[f'answer_{i}'] for i in range(10)]\n",
        "  correct_answers = [x for x in correct_answers if x]\n",
        "\n",
        "  evaluation = evaluation_template.format(\n",
        "      correct_answers=' | '.join(correct_answers),\n",
        "      response=response,\n",
        "  )\n",
        "\n",
        "  fresheval = call_fresheval(\n",
        "      model_name,\n",
        "      prefix,\n",
        "      question,\n",
        "      response,\n",
        "      correct_answers,\n",
        "      evaluation,\n",
        "  )\n",
        "  is_valid_eval, eval = extract_ratings(fresheval)\n",
        "  if is_valid_eval:\n",
        "    print('Done')\n",
        "\n",
        "  while not is_valid_eval:\n",
        "    print('Invalid evaluation, reevaluating...')\n",
        "    fresheval = call_fresheval(\n",
        "        model_name,\n",
        "        prefix,\n",
        "        question,\n",
        "        response,\n",
        "        correct_answers,\n",
        "        evaluation,\n",
        "    )\n",
        "    is_valid_eval, eval = extract_ratings(fresheval)\n",
        "    if is_valid_eval:\n",
        "      print('Done')\n",
        "  freshevals.append({'rating': eval['rating'], 'explanation': fresheval})\n",
        "\n",
        "df_eval = pd.DataFrame(freshevals)\n",
        "\n",
        "# Write results to the spreadsheet\n",
        "rating_list = worksheet.range('E4:E13')\n",
        "explanation_list = worksheet.range('F4:F13')\n",
        "\n",
        "for cell, explanation in zip(rating_list, df_eval.rating.to_list()):\n",
        "  cell.value = explanation\n",
        "\n",
        "for cell, explanation in zip(explanation_list, df_eval.explanation.to_list()):\n",
        "  cell.value = explanation\n",
        "\n",
        "worksheet.update_cells(rating_list)\n",
        "worksheet.update_cells(explanation_list)\n",
        "\n",
        "# Download evaluations\n",
        "outfile = 'fresheval_strict.csv'\n",
        "df_eval.to_csv(outfile, header=True, index=True)\n",
        "files.download(outfile)\n"
      ],
      "metadata": {
        "id": "SMf6R0VHfzx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "3c65fb2e-a67a-4edd-95d1-0d686d25c45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating example id=0...\n",
            "Done\n",
            "Evaluating example id=1...\n",
            "Done\n",
            "Evaluating example id=2...\n",
            "Done\n",
            "Evaluating example id=3...\n",
            "Done\n",
            "Evaluating example id=4...\n",
            "Done\n",
            "Evaluating example id=5...\n",
            "Done\n",
            "Evaluating example id=6...\n",
            "Done\n",
            "Evaluating example id=7...\n",
            "Done\n",
            "Evaluating example id=8...\n",
            "Done\n",
            "Evaluating example id=9...\n",
            "Done\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0db6a2aa-7160-4720-87c2-1e18fbe5b942\", \"fresheval_strict.csv\", 2854)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval[:num_evals]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "HCdw8F-MZZlO",
        "outputId": "ae1b6659-ec51-46c9-de2c-c2d32da89235"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  rating                                        explanation\n",
              "0  FALSE  The question contains a false premise. The res...\n",
              "1  FALSE  The question contains a false premise. The res...\n",
              "2   TRUE  The question contains a false premise. The res...\n",
              "3   TRUE  The question contains a false premise. The res...\n",
              "4  FALSE  The question is based on a common misconceptio...\n",
              "5   TRUE  The question contains a false premise. The res...\n",
              "6  FALSE  The question contains a false premise. The res...\n",
              "7  FALSE  The question contains a false premise. The res...\n",
              "8  FALSE  The question contains a false premise. The res...\n",
              "9  FALSE  The question contains a false premise. The res..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cadc527-f3a9-40e2-a331-f0b2a0f35b15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>explanation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FALSE</td>\n",
              "      <td>The question contains a false premise. The res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FALSE</td>\n",
              "      <td>The question contains a false premise. The res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRUE</td>\n",
              "      <td>The question contains a false premise. The res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRUE</td>\n",
              "      <td>The question contains a false premise. The res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FALSE</td>\n",
              "      <td>The question is based on a common misconceptio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TRUE</td>\n",
              "      <td>The question contains a false premise. The res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>FALSE</td>\n",
              "      <td>The question contains a false premise. The res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>FALSE</td>\n",
              "      <td>The question contains a false premise. The res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>FALSE</td>\n",
              "      <td>The question contains a false premise. The res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>FALSE</td>\n",
              "      <td>The question contains a false premise. The res...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cadc527-f3a9-40e2-a331-f0b2a0f35b15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9cadc527-f3a9-40e2-a331-f0b2a0f35b15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9cadc527-f3a9-40e2-a331-f0b2a0f35b15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a7f65875-8bfe-4aa3-bc80-a7d38e299e1b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7f65875-8bfe-4aa3-bc80-a7d38e299e1b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a7f65875-8bfe-4aa3-bc80-a7d38e299e1b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_eval[:num_evals]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"TRUE\",\n          \"FALSE\"\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"explanation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"The question contains a false premise. The response fails to debunk the question's false premise by incorrectly stating that Mark Cuban sold the Dallas Mavericks in February 2018. Thus, the response is not credited.\\nevaluation: incorrect\",\n          \"The question contains a false premise. The response correctly debunks the question's false premise (i.e., it points out that Leonardo DiCaprio does not have any children). However, the response fails to provide a current answer and instead relies on outdated information without confirming its continued accuracy. Thus, the response is not credited.\\nevaluation: incorrect\"\n        ],\n        \"num_unique_values\": 10,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}
